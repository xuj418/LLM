{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d23ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d86012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv, dotenv_values\n",
    "\n",
    "env_values = dotenv_values()\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY'] = env_values[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6cefdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyo88\\anaconda3\\envs\\deep\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48f7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"What is the best name to describe a company that makes {product}?\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7845ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyo88\\anaconda3\\envs\\deep\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"MacBook Makers Co.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"macbook\"\n",
    "\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8489890",
   "metadata": {},
   "source": [
    "## SequtiaChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cea8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "llm = ChatOpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de445683",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_template(\"What is the best name to describe a company that makes {product}?\")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\"Write 20 words that descibe the a company that makes {product}\")\n",
    "chain_second = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf31834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chain=SimpleSequentialChain(chains=[chain_one, chain_second], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3efc6fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"MacBook Makers Inc.\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mInnovative, sleek, high-tech, reliable, customer-oriented, creative, efficient, responsive, cutting-edge, prestigious, reputable, advanced, user-friendly, modern, stylish, productive, elite, progressive, top-notch, quality.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Innovative, sleek, high-tech, reliable, customer-oriented, creative, efficient, responsive, cutting-edge, prestigious, reputable, advanced, user-friendly, modern, stylish, productive, elite, progressive, top-notch, quality.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309798f",
   "metadata": {},
   "source": [
    "## SequentialChain\n",
    "## chain1 -> chain2 -> chain3 -> chain4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dd1d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "llm = ChatOpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7450df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_template(\"Translate the following review to English:\"\n",
    "                                                \"\\\\{review}\")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key=\"English_review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dca7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\"Can you summerize the following review to one sentence: \"\n",
    "                                                 \"\\\\{English_review}\")\n",
    "chain_second = LLMChain(llm=llm, prompt=second_prompt, output_key=\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d95386cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_prompt = ChatPromptTemplate.from_template(\"What language is the fowlling review: {review}\")\n",
    "chain_third = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60ce3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_prompt = ChatPromptTemplate.from_template(\"Write a follow up response to the following summary in the specified language: \"\n",
    "                                                 \"\\\\summary:{summary}, language:{language}\")\n",
    "chain_fourth = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2ad2a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential = SequentialChain(chains=[chain_one, chain_second, chain_third, chain_fourth],\n",
    "                               input_variables=[\"review\"],\n",
    "                               output_variables=[\"English_review\", \"summary\", \"language\", \"response\"],\n",
    "                               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05cca668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyo88\\anaconda3\\envs\\deep\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': '这个面包太好吃了，软软的，白白的，非常香，过几天再来买',\n",
       " 'English_review': 'This bread is so delicious, soft, white, very fragrant, I will come back to buy again in a few days.',\n",
       " 'summary': 'The reviewer highly recommends the delicious, soft, and fragrant bread and plans to repurchase it soon.',\n",
       " 'language': 'This review is in Chinese. It translates to: \"This bread is so delicious, soft, white, very fragrant, I will come back to buy more in a few days.\"',\n",
       " 'response': '非常感谢您的推荐！确实，那种美味、柔软、芳香的面包让人难以忘怀。我也计划近期再次光顾购买。希望您也能尽快品尝到这款美味的面包！感谢您的宝贵意见！'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential(\"这个面包太好吃了，软软的，白白的，非常香，过几天再来买\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c41d83",
   "metadata": {},
   "source": [
    "## MultiPromptChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9580870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_template = \"\"\"\n",
    "    You are very know about film. You have seen a lot of film, and you can review the film.\n",
    "    Here is the question:{input}\n",
    "\"\"\"\n",
    "\n",
    "food_template = \"\"\"\n",
    "    You are very know about food. You have eat a lot of delicious food, and you can make them.\n",
    "    Here is the question:{input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4411fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_info = [\n",
    "    {\n",
    "        \"name\": \"cooking\",\n",
    "        \"description\": \"Good for answering question about cooking\",\n",
    "        \"prompt_template\": food_template\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"name\": \"film\",\n",
    "        \"description\": \"Good for answering question about film\",\n",
    "        \"prompt_template\": film_template\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86bdcad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e970bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c50ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chain = {}\n",
    "\n",
    "for info in prompt_info:\n",
    "    name = info[\"name\"]\n",
    "    prompt_template = info[\"prompt_template\"]  \n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)  \n",
    "    chain = LLMChain(llm=llm, prompt=prompt)   \n",
    "    destination_chain[name] = chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0024f41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cooking': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='\\n    You are very know about food. You have eat a lot of delicious food, and you can make them.\\n    Here is the question:{input}\\n'))]), llm=ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.0, openai_api_key='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', openai_proxy='')),\n",
       " 'film': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='\\n    You are very know about film. You have seen a lot of film, and you can review the film.\\n    Here is the question:{input}\\n'))]), llm=ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.0, openai_api_key='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', openai_proxy=''))}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a1ae541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking: Good for answering question about cooking',\n",
       " 'film: Good for answering question about film']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_info]\n",
    "destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b8d06f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cooking: Good for answering question about cooking\\nfilm: Good for answering question about film'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations_str = \"\\n\".join(destinations)\n",
    "destinations_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6156e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "185feaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d90543ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"\n",
    "<< CANDIDATE PROMPTS >>\n",
    "Return a markdown code\n",
    "'''json\n",
    "{{{{\n",
    "    \"destination\": string\n",
    "    \"next_inputs\": string \n",
    "}}}}\n",
    "'''\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the '''json )>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a05ab41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<< CANDIDATE PROMPTS >>\\nReturn a markdown code\\n\\'\\'\\'json\\n{{\\n    \"destination\": string\\n    \"next_inputs\": string \\n}}\\n\\'\\'\\'\\n\\n<< CANDIDATE PROMPTS >>\\ncooking: Good for answering question about cooking\\nfilm: Good for answering question about film\\n\\n<< INPUT >>\\n{input}\\n\\n<< OUTPUT (remember to include the \\'\\'\\'json )>>\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations = destinations_str)\n",
    "router_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15c68176",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = PromptTemplate(\n",
    "    template=router_template, \n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c57833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "242fa991",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_chain=MultiPromptChain(router_chain=router_chain,\n",
    "                            destination_chains=destination_chain,\n",
    "                            default_chain=default_chain, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80675d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "film: {'input': 'Do you have a specific question about a Transformer movie or character?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, I do! Which Transformer movie do you think had the best portrayal of Optimus Prime and why?'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_chain.run(\"Do you know Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8bf9a16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "cooking: {'input': 'sushi'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sushi is a popular Japanese dish that typically consists of vinegared rice, raw or cooked seafood, vegetables, and sometimes tropical fruits. It is often served with soy sauce, wasabi, and pickled ginger. Sushi can be made in various forms such as nigiri (hand-pressed sushi), maki (sushi rolls), sashimi (sliced raw fish), and temaki (hand rolls). It requires skill and precision to make sushi, as well as fresh and high-quality ingredients. Have you ever tried making sushi at home or do you prefer to enjoy it at a sushi restaurant?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_chain.run(\"Do you know sushi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49027d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
